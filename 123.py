import os
import re
from typing import Annotated, TypedDict, Literal
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langgraph.graph import StateGraph, END, add_messages

# --- 1. åˆå§‹åŒ–èˆ‡é˜²å´©æ½°è¨­å®š ---
llm = ChatOpenAI(
    base_url="https://ws-02.wade0426.me/v1",
    api_key="", # ç…§æ•™æç•™ç©º
    model="google/gemma-3-27b-it",
    temperature=0,
    timeout=20,       # é€£ç·šè¶…é 20 ç§’è‡ªå‹•æ–·é–‹
    max_retries=2     # å¤±æ•—è‡ªå‹•é‡è©¦
)

# --- 2. ç‹€æ…‹å®šç¾© ---
class AgentState(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]
    knowledge_base: str
    is_hit: bool
    loop_count: int

# --- 3. ç¯€é»åŠŸèƒ½ ---

def check_cache_node(state: AgentState):
    """æª¢æŸ¥å•é¡Œæ˜¯å¦å‘½ä¸­å¿«å–"""
    query = state["messages"][-1].content.lower()
    # åªè¦åŒ…å« langchain æˆ– åŸºç¤æ¦‚å¿µ å°±ç›´æ¥å‡ºç­”æ¡ˆ
    if "langchain" in query or "åŸºç¤" in query:
        return {"is_hit": True, "knowledge_base": "å¿«å–è³‡æ–™ï¼šLangChain æ˜¯ä¸€å€‹æ—¨åœ¨ç°¡åŒ– LLM æ‡‰ç”¨é–‹ç™¼çš„æ¡†æ¶ã€‚", "loop_count": 0}
    return {"is_hit": False, "knowledge_base": "", "loop_count": 0}

def planner_node(state: AgentState):
    """æ±ºç­–ä¸­å¿ƒï¼šåˆ¤æ–·è³‡æ–™å¤ ä¸å¤ """
    kb = state.get("knowledge_base", "")
    prompt = f"å•é¡Œï¼š{state['messages'][0].content}\nè³‡æ–™ï¼š{kb}\nè³‡æ–™æ˜¯å¦è¶³å¤ å›ç­”ï¼Ÿåªéœ€å› YES æˆ– NOã€‚"
    try:
        res = llm.invoke([HumanMessage(content=prompt)])
        # æ¸…ç†æ¨¡å‹å¯èƒ½å™´å‡ºçš„æ¨™ç±¤å¦‚ <|im_end|>
        clean = re.sub(r'<.*?>', '', res.content).strip().upper()
    except:
        clean = "YES" # æ–·ç·šæ™‚å¼·åˆ¶çµæŸæœå°‹
    return {"messages": [AIMessage(content=clean)]}

def query_gen_node(state: AgentState):
    """ç”Ÿæˆé—œéµå­—ç¯€é»"""
    return {"messages": [AIMessage(content="ç³»çµ±æ­£åœ¨æœå°‹æ›´å¤šè³‡è¨Š...")], "loop_count": state["loop_count"] + 1}

def search_tool_node(state: AgentState):
    """æœå°‹å·¥å…·ç¯€é»"""
    return {"knowledge_base": "æœå°‹çµæœï¼šLangGraph æ˜¯ LangChain çš„é€²éšæ“´å±•ï¼Œå°ˆé–€è™•ç†æœ‰å¾ªç’°é‚è¼¯çš„å¤šä»£ç†äººå·¥ä½œæµã€‚"}

def final_answer_node(state: AgentState):
    """ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆç¯€é»"""
    kb = state.get("knowledge_base", "ç›®å‰æŸ¥ä¸åˆ°æ›´å¤šè³‡è¨Šã€‚")
    prompt = f"æ ¹æ“šè³‡æ–™å›ç­”å•é¡Œï¼š{kb}"
    try:
        res = llm.invoke([HumanMessage(content=prompt)])
        final = re.sub(r'<.*?>', '', res.content).strip()
    except:
        final = f"é€£ç·šç•°å¸¸ï¼Œæ ¹æ“šç¾æœ‰è³‡æ–™å›è¦†ï¼š{kb}"
    return {"messages": [AIMessage(content=final)]}

# --- 4. è·¯ç”±èˆ‡å·¥ä½œæµæ§‹å»º ---

def cache_router(state: AgentState):
    return "hit" if state["is_hit"] else "miss"

def decision_router(state: AgentState):
    if state["loop_count"] >= 2: # æœ€å¤šæœå…©æ¬¡ï¼Œé˜²æ­¢æ­»è¿´åœˆ
        return "sufficient"
    last_msg = state["messages"][-1].content.upper()
    return "sufficient" if "YES" in last_msg else "insufficient"

workflow = StateGraph(AgentState)
workflow.add_node("check_cache", check_cache_node)
workflow.add_node("planner", planner_node)
workflow.add_node("query_gen", query_gen_node)
workflow.add_node("search_tool", search_tool_node)
workflow.add_node("final_answer", final_answer_node)

workflow.set_entry_point("check_cache")
workflow.add_conditional_edges("check_cache", cache_router, {"hit": "final_answer", "miss": "planner"})
workflow.add_conditional_edges("planner", decision_router, {"sufficient": "final_answer", "insufficient": "query_gen"})
workflow.add_edge("query_gen", "search_tool")
workflow.add_edge("search_tool", "planner")
workflow.add_edge("final_answer", END)

app = workflow.compile()

# --- 5. äº’å‹•å¼ä»‹é¢ ---
if __name__ == "__main__":
    print("\n--- ğŸ¤– è‡ªå‹•æŸ¥è­‰ AI å•Ÿå‹• (è¼¸å…¥ q çµæŸ) ---")
    while True:
        user_input = input("\nè«‹è¼¸å…¥ä½ çš„å•é¡Œ: ")
        if user_input.lower() == 'q': break
        
        init_state = {"messages": [HumanMessage(content=user_input)], "knowledge_base": "", "is_hit": False, "loop_count": 0}
        
        for event in app.stream(init_state):
            for node, data in event.items():
                print(f"ğŸ“ ç¯€é»: [{node}]")
                if "messages" in data:
                    print(f"   å…§å®¹: {data['messages'][-1].content}")