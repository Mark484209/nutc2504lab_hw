import time
import requests
import operator
from pathlib import Path
from typing import Annotated, TypedDict
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI

# ==========================================
# 1. ASR èªéŸ³è¾¨è­˜éƒ¨åˆ† (å–å¾— 20 ç§’éŸ³æª”çš„å®Œæ•´å…§å®¹)
# ==========================================
BASE = "https://3090api.huannago.com"
CREATE_URL = f"{BASE}/api/v1/subtitle/tasks"
WAV_PATH = "/home/pc-49/Downloads/Podcast_EP14_30s.wav" 
auth = ("nutc2504", "nutc2504")

def get_asr_results():
    print("æ­£åœ¨ä¸Šå‚³éŸ³æª”é€²è¡Œè¾¨è­˜...")
    with open(WAV_PATH, "rb") as f:
        r = requests.post(CREATE_URL, files={"audio": f}, timeout=60, auth=auth)
    r.raise_for_status()
    task_id = r.json()["id"]
    
    txt_url = f"{BASE}/api/v1/subtitle/tasks/{task_id}/subtitle?type=TXT"
    srt_url = f"{BASE}/api/v1/subtitle/tasks/{task_id}/subtitle?type=SRT"

    def wait_download(url: str):
        for _ in range(600):
            try:
                resp = requests.get(url, timeout=(5, 60), auth=auth)
                if resp.status_code == 200: return resp.text
            except: pass
            time.sleep(2)
        return None

    print(f"ç­‰å¾…è½‰éŒ„å®Œæˆ (Task ID: {task_id})...")
    return wait_download(srt_url), wait_download(txt_url)

# ==========================================
# 2. LangGraph è¨­å®šèˆ‡å®šç¾©
# ==========================================
llm = ChatOpenAI(
    base_url="https://ws-02.wade0426.me/v1",
    api_key="", 
    model="google/gemma-3-27b-it",
    temperature=0
)

def merge_dict(left: dict, right: dict) -> dict:
    new_dict = left.copy()
    new_dict.update(right)
    return new_dict

class GraphState(TypedDict):
    srt_content: str
    txt_content: str
    results: Annotated[dict, merge_dict]

def asr_node(state: GraphState):
    return {"results": {"status": "Processing"}}

def minutes_taker_node(state: GraphState):
    prompt = f"è«‹å°‡ä»¥ä¸‹ SRT å…§å®¹è½‰ç‚º Markdown è¡¨æ ¼ (æ™‚é–“|ç™¼è¨€å…§å®¹):\n\n{state['srt_content']}"
    res = llm.invoke(prompt)
    return {"results": {"minutes": res.content}}

def summarizer_node(state: GraphState):
    prompt = f"è«‹æ‘˜è¦ä»¥ä¸‹å…§å®¹ (åŒ…å«æ±ºç­–èˆ‡å¾…è¾¦äº‹é …):\n\n{state['txt_content']}"
    res = llm.invoke(prompt)
    return {"results": {"summary": res.content}}

def writer_node(state: GraphState):
    summary = state["results"].get("summary", "")
    minutes = state["results"].get("minutes", "")
    # ä¾ç…§åœ–ç‰‡ 40 æ ¼å¼çµ„åˆ
    report = f"# ğŸ“‘ æ™ºæ…§æœƒè­°ç´€éŒ„å ±å‘Š\n\n## ğŸ¯ é‡é»æ‘˜è¦ (Executive Summary)\n{summary}\n\n---\n## ğŸ“ è©³ç´°é€å­—ç¨¿ (Detailed Minutes)\n{minutes}"
    return {"results": {"final_report": report}}

# å»ºç«‹åœ–çµæ§‹
workflow = StateGraph(GraphState)
workflow.add_node("asr", asr_node)
workflow.add_node("minutes_taker", minutes_taker_node)
workflow.add_node("summarizer", summarizer_node)
workflow.add_node("writer", writer_node)
workflow.set_entry_point("asr")
workflow.add_edge("asr", "minutes_taker")
workflow.add_edge("asr", "summarizer")
workflow.add_edge("minutes_taker", "writer")
workflow.add_edge("summarizer", "writer")
workflow.add_edge("writer", END)
app = workflow.compile()

# ==========================================
# 3. åŸ·è¡Œæµç¨‹èˆ‡å­˜æª”
# ==========================================
srt_data, txt_data = get_asr_results() # é€™è£¡æœƒå–å¾—å®Œæ•´ 20 ç§’å…§å®¹

if srt_data and txt_data:
    print("--- æ™ºæ…§æœƒè­°åŠ©ç†é–‹å§‹åˆ†æ ---")
    inputs = {"srt_content": srt_data, "txt_content": txt_data}
    final_output = app.invoke(inputs)
    
    report_content = final_output["results"]["final_report"]
    
    # å°å‡ºçµæœ
    print(report_content)
    
    # å­˜æª” (è§£æ±ºã€Œæª”æ¡ˆæ²’æœ‰å‡ºä¾†ã€çš„å•é¡Œ)
    out_dir = Path("./out")
    out_dir.mkdir(exist_ok=True)
    report_path = out_dir / "meeting_report.md"
    report_path.write_text(report_content, encoding="utf-8")
    print(f"\nâœ… å ±å‘Šå·²å„²å­˜è‡³: {report_path}")
else:
    print("ASR è½‰éŒ„å¤±æ•—ã€‚")