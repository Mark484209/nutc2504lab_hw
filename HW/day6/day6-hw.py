import os
import pandas as pd
from datasets import Dataset
from ragas import evaluate
from ragas.metrics import (
    faithfulness,
    answer_relevancy,
    context_precision,
    context_recall
)

# å‡è¨­ä½ ä½¿ç”¨ OpenAI ä½œç‚ºè©•åˆ†å“¡ï¼Œéœ€è¨­å®š API Key
os.environ["OPENAI_API_KEY"] = "ä½ çš„_API_KEY"

BASE_DIR = os.path.dirname(os.path.abspath(__file__))

def get_real_ai_answer(question):
    """
    é€™è£¡æ‡‰æ¥ä¸Šä½ çœŸæ­£çš„ RAG æª¢ç´¢é‚è¼¯ã€‚
    ç›®å‰å…ˆå›å‚³æ¨¡æ“¬å…§å®¹ï¼Œä½†è©•åˆ†æœƒç”± Ragas çœŸæ­£åŸ·è¡Œã€‚
    """
    # æ¨¡æ“¬æª¢ç´¢åˆ°çš„åƒè€ƒå…§å®¹ (Context)
    retrieved_contexts = ["é€™æ˜¯å¾è³‡æ–™åº«æª¢ç´¢å‡ºä¾†çš„åŸå§‹æ®µè½å…§å®¹..."]
    # æ¨¡æ“¬ LLM ç”Ÿæˆçš„ç­”æ¡ˆ
    generated_answer = f"æ ¹æ“šæª¢ç´¢å…§å®¹ï¼Œé€™é¡Œçš„å›ç­”æ˜¯..."
    
    return generated_answer, retrieved_contexts

def main():
    input_file = os.path.join(BASE_DIR, "day6_HW_questions.csv")
    output_file = os.path.join(BASE_DIR, "questions_evaluated.csv")

    if not os.path.exists(input_file):
        print("âŒ æ‰¾ä¸åˆ°åŸå§‹æª”æ¡ˆ")
        return

    df = pd.read_csv(input_file)
    df.columns = [c.lower().strip() for c in df.columns]

    data_samples = {
        "question": [],
        "answer": [],
        "contexts": [],
        "ground_truth": [] # å¦‚æœä½ æœ‰æ¨™æº–ç­”æ¡ˆçš„è©±
    }

    # 1. è·‘ RAG æµç¨‹ç²å–ç­”æ¡ˆèˆ‡æª¢ç´¢å…§å®¹
    for _, row in df.iterrows():
        q_text = row['questions']
        ans, ctx = get_real_ai_answer(q_text)
        
        data_samples["question"].append(q_text)
        data_samples["answer"].append(ans)
        data_samples["contexts"].append(ctx)
        # å¦‚æœ csv è£¡æœ¬ä¾†å°±æœ‰æ­£ç¢ºç­”æ¡ˆï¼Œè«‹å¡«å…¥ï¼›è‹¥ç„¡ï¼Œé€™æ¬„æœƒå½±éŸ¿ Recall è¨ˆç®—
        data_samples["ground_truth"].append(row.get('ground_truth', "é è¨­æ¨™æº–ç­”æ¡ˆ"))

    # 2. è½‰æ›ç‚º Ragas æ‰€éœ€çš„ Dataset æ ¼å¼
    dataset = Dataset.from_dict(data_samples)

    # 3. å‘¼å« AI é€²è¡ŒçœŸæ­£çš„è©•åˆ†
    print("ğŸš€ æ­£åœ¨èª¿ç”¨ LLM é€²è¡ŒæŒ‡æ¨™è¨ˆç®— (é€™å¯èƒ½éœ€è¦ä¸€é»æ™‚é–“ä¸¦æ¶ˆè€— Token)...")
    score_result = evaluate(
        dataset,
        metrics=[
            faithfulness,
            answer_relevancy,
            context_precision,
            context_recall
        ],
    )

    # 4. æ•´ç†çµæœä¸¦å­˜æª”
    final_df = score_result.to_pandas()
    final_df.to_csv(output_file, index=False, encoding='utf-8-sig')

    print(f"âœ… è©•ä¼°å®Œæˆï¼è‡ªå‹•è¨ˆç®—çš„åˆ†æ•¸å·²å­˜è‡³: {output_file}")

if __name__ == "__main__":
    main()