import os
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams, PointStruct
from sentence_transformers import SentenceTransformer

# ==========================================
# 1. å®šç¾©å°è£å‡½æ•¸èˆ‡é¡åˆ¥
# ==========================================

class SimpleVDB:
    def __init__(self, collection_name="day5_assignment"):
        """åˆå§‹åŒ–è³‡æ–™åº«èˆ‡æ¨¡å‹"""
        self.client = QdrantClient(":memory:")
        self.collection_name = collection_name
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.vector_size = 384
        
        # å»ºç«‹ Collection
        self.client.create_collection(
            collection_name=self.collection_name,
            vectors_config=VectorParams(size=self.vector_size, distance=Distance.COSINE),
        )

    def add_documents(self, documents: list):
        """å‡½æ•¸ï¼šåµŒå…¥ä¸¦ä¸Šå‚³æ–‡ä»¶"""
        vectors = self.model.encode(documents)
        points = [
            PointStruct(
                id=i, 
                vector=vectors[i].tolist(), 
                payload={"content": documents[i]}
            )
            for i in range(len(documents))
        ]
        self.client.upsert(collection_name=self.collection_name, points=points)
        print(f"âœ… æˆåŠŸåµŒå…¥ {len(points)} ç­†è³‡æ–™åˆ° Qdrant")

    def query(self, text: str, top_k: int = 2):
        """å‡½æ•¸ï¼šæœå°‹æœ€ç›¸é—œçš„å…§å®¹"""
        query_vector = self.model.encode(text).tolist()
        search_result = self.client.query_points(
            collection_name=self.collection_name,
            query=query_vector,
            limit=top_k
        ).points
        return search_result

# ==========================================
# 2. åŸ·è¡Œä¸»ç¨‹å¼
# ==========================================

def run_vdb_demo():
    # åˆå§‹åŒ–
    vdb = SimpleVDB()

    # æº–å‚™è³‡æ–™
    raw_data = [
        "Qdrant æ˜¯ä¸€æ¬¾é«˜æ•ˆèƒ½çš„å‘é‡è³‡æ–™åº«ã€‚",
        "Python æ˜¯é–‹ç™¼ AI æ‡‰ç”¨çš„é¦–é¸èªè¨€ã€‚",
        "å‘é‡æª¢ç´¢æ¯”å‚³çµ±é—œéµå­—æœå°‹æ›´èƒ½ç†è§£èªç¾©ã€‚",
        "ä»Šå¤©çš„å¤©æ°£éå¸¸é©åˆåœ¨æˆ¶å¤–å¯«ç¨‹å¼ã€‚",
        "Github æ˜¯ç¨‹å¼è¨­è¨ˆå¸«ç®¡ç†ç‰ˆæœ¬çš„å¥½å¹«æ‰‹ã€‚",
        "å­¸ç¿’æ–°çš„æŠ€è¡“é›–ç„¶è¾›è‹¦ï¼Œä½†éå¸¸æœ‰æˆå°±æ„Ÿã€‚"
    ]
    
    # å‘¼å«æ–°å¢å‡½æ•¸
    vdb.add_documents(raw_data)

    # æ¸¬è©¦æŸ¥è©¢
    test_queries = ["æˆ‘æƒ³å­¸ç¿’æ€éº¼ç®¡ç†ä»£ç¢¼", "AI é–‹ç™¼èªè¨€"]

    for q in test_queries:
        print(f"\nğŸ” [æª¢ç´¢æŸ¥è©¢]: {q}")
        print("-" * 40)
        
        # å‘¼å«æŸ¥è©¢å‡½æ•¸
        hits = vdb.query(q)
        
        if not hits:
            print("æ‰¾ä¸åˆ°ç›¸é—œçµæœã€‚")
        else:
            for i, hit in enumerate(hits):
                content = hit.payload['content']
                score = hit.score
                print(f"çµæœ {i+1}: {content} (ç›¸ä¼¼åº¦: {score:.4f})")

if __name__ == "__main__":
    run_vdb_demo()